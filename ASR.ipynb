{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c67c823",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import torch\n",
    "import librosa\n",
    "from transformers import pipeline\n",
    "\n",
    "def load_audio(path, sr=16000):\n",
    "    audio, _ = librosa.load(path, sr=sr, mono=True)\n",
    "    return audio\n",
    "\n",
    "def ASR_text(audio_path):\n",
    "    # Good baseline model\n",
    "    model_id = \"facebook/wav2vec2-base-960h\"\n",
    "\n",
    "    device = -1  # CPU\n",
    "    asr = pipeline(\n",
    "        \"automatic-speech-recognition\",\n",
    "        model=model_id,\n",
    "        device=device,\n",
    "        chunk_length_s=20,   # chunking helps longer files\n",
    "        stride_length_s=4\n",
    "    )\n",
    "\n",
    "    audio = load_audio(audio_path, sr=16000)\n",
    "    out = asr(audio)\n",
    "    print(out[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c6e18e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ASR_text(\"Audio/test_1.wav\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
